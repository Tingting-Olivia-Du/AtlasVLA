# 推荐配置：28GB可用显存
# 基于你的GPU状态：RTX 6000 Ada (49GB总显存，28GB可用)

# Model configuration
model:
  vggt_checkpoint: "facebook/VGGT-1B"
  lang_encoder_name: "meta-llama/Llama-2-7b-hf"
  freeze_vggt: true  # ✅ 冻结VGGT（节省显存）
  freeze_lang_encoder: true  # ✅ 也冻结LLaMA（推荐开始，如果微调LLaMA需要更多显存）
  geom_output_dim: 512
  fusion_hidden_dim: 1024
  action_dim: 7
  use_pointnet: true
  use_pose: true

# Data configuration
data:
  data_dir: "/path/to/libero/data"  # 更新这个路径
  train_split: "train"
  val_split: "val"
  image_size: 518  # VGGT输入尺寸
  use_wrist_camera: true
  batch_size: 8  # ✅ 可以保持8（如果只训练融合模块）
  num_workers: 4

# Training configuration
training:
  num_epochs: 50
  learning_rate: 1e-4  # 基础学习率（多GPU时会自动缩放）
  weight_decay: 0.01
  warmup_steps: 1000
  gradient_accumulation_steps: 1  # ✅ 如果只训练融合模块，可以保持1
  
  # Loss weights
  loss:
    pose_weight: 1.0
    gripper_weight: 0.5
    pose_loss_type: "smooth_l1"
    gripper_loss_type: "l1"
  
  # Logging intervals
  log_interval: 100
  val_interval: 1000
  save_interval: 5000

# Checkpointing
checkpoint:
  save_dir: "./checkpoints"
  resume_from: null

# Experiment tracking
wandb:
  enabled: false
  project: "atlas-vla"
  entity: null
  name: null
  tags: []
  notes: ""
  save_code: true
  resume: "allow"

# Device
device: "cuda"
