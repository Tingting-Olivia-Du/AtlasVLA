# VLA-VGGT æ¶æ„åˆ†æå’Œå¤šæ¨¡æ€å¤„ç†

## ğŸ“‹ ç›®å½•
- [æ¶æ„æ¦‚è¿°](#æ¶æ„æ¦‚è¿°)
- [å¤šæ¨¡æ€å¤„ç†åˆ†æ](#å¤šæ¨¡æ€å¤„ç†åˆ†æ)
- [å®ç°æ–¹æ¡ˆ](#å®ç°æ–¹æ¡ˆ)
- [è®­ç»ƒæŒ‡å—](#è®­ç»ƒæŒ‡å—)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## æ¶æ„æ¦‚è¿°

### è®¾è®¡ç›®æ ‡
æ„å»ºä¸€ä¸ªåŸºäº VGGT çš„ Vision-Language-Action (VLA) æ¨¡å‹ï¼Œç”¨äºæœºå™¨äººæ“ä½œä»»åŠ¡ã€‚

### æ ¸å¿ƒç»„ä»¶

```
Input: Image + Language Instruction
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vision Encoder  â”‚         â”‚Language Encoder  â”‚
â”‚                 â”‚         â”‚                  â”‚
â”‚ Option A:       â”‚         â”‚ Qwen3-0.6B-Base  â”‚
â”‚  - Direct Patch â”‚         â”‚                  â”‚
â”‚  - Embedding    â”‚         â”‚ [B, L, 1024]     â”‚
â”‚                 â”‚         â”‚      â†“           â”‚
â”‚ Option B:       â”‚         â”‚  Projector       â”‚
â”‚  - DINO/CLIP    â”‚         â”‚      â†“           â”‚
â”‚  - + Projector  â”‚         â”‚ [B, L, 768]      â”‚
â”‚                 â”‚         â”‚                  â”‚
â”‚ [B, N, 768]     â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
         â”‚                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Token Fusion        â”‚
         â”‚  - Concat            â”‚
         â”‚  - Type Embeddings   â”‚
         â”‚  [B, N+L, 768]       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  VGGT Backbone       â”‚
         â”‚                      â”‚
         â”‚  Option A:           â”‚
         â”‚  - facebook/vggt (HF)â”‚
         â”‚  - Adapter Layer     â”‚
         â”‚                      â”‚
         â”‚  Option B:           â”‚
         â”‚  - Simplified VGGT   â”‚
         â”‚  - Graph Conv        â”‚
         â”‚  - Self-Attention    â”‚
         â”‚                      â”‚
         â”‚  [B, N+L, 768]       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Action Queries      â”‚
         â”‚  [B, 16, 768]        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Action Head         â”‚
         â”‚  (MLP)               â”‚
         â”‚  [B, T, action_dim]  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         Action Predictions
```

---

## å¤šæ¨¡æ€å¤„ç†åˆ†æ

### ğŸ”´ åŸå§‹å®ç°çš„é—®é¢˜

#### 1. VGGT ä¸æ˜¯ä» HuggingFace åŠ è½½
**é—®é¢˜**: 
- å½“å‰å®ç°æ˜¯ç®€åŒ–çš„ VGGT (åªæœ‰ Graph Conv + Self-Attention)
- åŸå§‹ facebook/vggt æ˜¯å¤æ‚çš„ Aggregator æ¶æ„ï¼Œä¸“ä¸ºè§†é¢‘åºåˆ—è®¾è®¡

**å½±å“**:
- ç¼ºå°‘ VGGT çš„å…³é”®ç‰¹æ€§: alternating attention, positional encoding
- æ— æ³•åˆ©ç”¨ VGGT çš„é¢„è®­ç»ƒæƒé‡

**è§£å†³æ–¹æ¡ˆ**:
- âœ… å®ç°äº† `VGGTAdapter` æ¥é€‚é… facebook/vggt
- âœ… æä¾› `SimpleVGGTBackbone` ä½œä¸ºå¿«é€Ÿå®éªŒçš„åå¤‡æ–¹æ¡ˆ

#### 2. Token ç»´åº¦å’Œç»“æ„ä¸åŒ¹é…
**é—®é¢˜**:
- facebook/vggt æœŸæœ›: `[B, S, 3, H, W]` (è§†é¢‘åºåˆ—)
- VLA ä»»åŠ¡: `[B, 3, H, W]` (å•å¸§å›¾åƒ)
- åŸå§‹ VGGT è¾“å‡º: ç”¨äº camera pose, depth, 3D points
- éœ€è¦: ç”¨äº action prediction çš„ç‰¹å¾

**å½±å“**:
- ç›´æ¥ä½¿ç”¨ facebook/vggt ä¼šæœ‰è¾“å…¥æ ¼å¼ä¸åŒ¹é…
- è¾“å‡ºç‰¹å¾ä¸é€‚åˆç›´æ¥ç”¨äºåŠ¨ä½œé¢„æµ‹

**è§£å†³æ–¹æ¡ˆ**:
- âœ… å®ç°é€‚é…å±‚å¤„ç†å•å¸§è¾“å…¥
- âœ… æ·»åŠ  action queries ä» VGGT ç‰¹å¾ä¸­æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯
- âœ… ç‰¹å¾æŠ•å½±å±‚å°† VGGT è¾“å‡ºæ˜ å°„åˆ°åŠ¨ä½œç©ºé—´

#### 3. å¤šæ¨¡æ€èåˆç­–ç•¥
**é—®é¢˜**:
- åŸå§‹ VGGT æ²¡æœ‰ language è¾“å…¥è®¾è®¡
- ç®€å•çš„ concat å¯èƒ½ä¸è¶³ä»¥æ•è· vision-language äº¤äº’

**å½±å“**:
- Language instruction å¯èƒ½æ— æ³•æœ‰æ•ˆæŒ‡å¯¼ visual attention
- Cross-modal ä¿¡æ¯äº¤æ¢å—é™

**è§£å†³æ–¹æ¡ˆ**:
- âœ… Token type embeddings åŒºåˆ†æ¨¡æ€
- âœ… åœ¨ VGGT çš„ attention å±‚ä¸­å®ç°éšå¼çš„ cross-modal äº¤äº’
- âœ… å¯é€‰çš„ cross-attention èåˆç­–ç•¥
- âœ… Graph structure: language chain + vision grid

#### 4. Vision Tower çš„é€‰æ‹©
**é—®é¢˜**:
- ç›´æ¥ patch embedding ä»é›¶å¼€å§‹å­¦ä¹ è§†è§‰ç‰¹å¾
- ç¼ºå°‘é¢„è®­ç»ƒçš„è§†è§‰å…ˆéªŒ

**å½±å“**:
- éœ€è¦æ›´å¤šæ•°æ®å’Œè®­ç»ƒæ—¶é—´
- å¯èƒ½æ— æ³•æ³›åŒ–åˆ°æ–°çš„ç‰©ä½“/åœºæ™¯

**è§£å†³æ–¹æ¡ˆ**:
- âœ… æ”¯æŒå¯é€‰çš„ vision tower (DINO, CLIP, SigLIP)
- âœ… çµæ´»çš„é…ç½®: å¯é€‰æ‹©ä½¿ç”¨æˆ–ä¸ä½¿ç”¨ vision tower
- âœ… Projector å±‚é€‚é…ä¸åŒçš„ vision tower

### âœ… æ”¹è¿›çš„å¤šæ¨¡æ€å¤„ç†æµç¨‹

#### Vision Path
```python
Image [B, 3, 224, 224]
  â†“
Option A: Direct Patch Embedding
  Conv2d(3 â†’ 768, kernel=16, stride=16)
  â†“
  [B, 196, 768]

Option B: Vision Tower
  DINOv2/CLIP/SigLIP
  â†“
  [B, 196, hidden_size]
  â†“
  Projector (hidden_size â†’ 768)
  â†“
  [B, 196, 768]
```

#### Language Path
```python
Instruction: "pick up the red block"
  â†“
Qwen3-0.6B-Base Tokenizer
  â†“
Token IDs [B, L]
  â†“
Qwen3-0.6B-Base Encoder
  â†“
[B, L, 1024]  # Qwen hidden size
  â†“
Projector (1024 â†’ 768)
  â†“
[B, L, 768]
```

#### Fusion
```python
Vision tokens: [B, 196, 768]
Language tokens: [B, 77, 768]
  â†“
Token Type Embeddings:
  - Vision: type_id = 0
  - Language: type_id = 1
  â†“
Concat: [B, 273, 768]
  â†“
Attention Mask:
  - Language can attend to: language + vision
  - Vision can attend to: vision + language
  â†“
Graph Structure:
  - Language: chain graph (sequential)
  - Vision: grid graph (spatial 2D)
  - Cross-modal: through attention, not graph
```

#### VGGT Processing
```python
Fused tokens: [B, 273, 768]
  â†“
VGGT Layers (6 layers):
  for each layer:
    - Graph Convolution (intra-modal)
    - Self-Attention (cross-modal)
    - FFN
  â†“
[B, 273, 768]
  â†“
Split:
  - Vision features: [B, 196, 768]
  - Language features: [B, 77, 768]
  â†“
Action Queries: [B, 16, 768]
  (learnable queries that aggregate info)
```

#### Action Prediction
```python
Global features: [B, 16, 768]
  or
Vision features: [B, 196, 768] (with spatial attention)
  â†“
MLP Action Head:
  Linear(768 â†’ 1024)
  LayerNorm
  ReLU
  Dropout
  Linear(1024 â†’ 1024)
  ReLU
  Linear(1024 â†’ action_dim * action_horizon)
  â†“
Actions: [B, T, action_dim]
  where T = action_horizon (e.g., 10)
```

---

## å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆå¯¹æ¯”

| ç‰¹æ€§ | ç®€åŒ–æ–¹æ¡ˆ | å®Œæ•´æ–¹æ¡ˆ |
|------|----------|----------|
| Vision | Direct Patch Embedding | DINOv2/CLIP |
| Language | Qwen2-0.5B (fallback) | Qwen3-0.6B-Base |
| VGGT | SimpleVGGTBackbone | facebook/vggt + Adapter |
| è®­ç»ƒé€Ÿåº¦ | å¿« | è¾ƒæ…¢ |
| å‚æ•°é‡ | ~50M | ~500M |
| æ€§èƒ½ | åŸºçº¿ | æ›´å¥½ |
| é€‚ç”¨åœºæ™¯ | å¿«é€Ÿå®éªŒã€è°ƒè¯• | æœ€ç»ˆæ¨¡å‹ã€å‘å¸ƒ |

### é…ç½®æ–‡ä»¶

#### 1. ç®€åŒ–é…ç½® (`configs/train_simple.yaml`)
```yaml
use_vision_tower: false
use_pretrained_vggt: false
language_model: "Qwen/Qwen2-0.5B"
freeze_language: true
batch_size: 32
```

é€‚åˆ:
- å¿«é€Ÿå®éªŒå’Œè°ƒè¯•
- èµ„æºå—é™çš„ç¯å¢ƒ
- éªŒè¯æ•°æ®pipeline

#### 2. ä¸­ç­‰é…ç½® (`configs/train_with_dinov2.yaml`)
```yaml
use_vision_tower: true
vision_tower_name: "facebook/dinov2-base"
use_pretrained_vggt: false
language_model: "Qwen/Qwen3-0.6B-Base"
batch_size: 24
```

é€‚åˆ:
- åˆ©ç”¨è§†è§‰é¢„è®­ç»ƒ
- å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦

#### 3. å®Œæ•´é…ç½® (`configs/train_full.yaml`)
```yaml
use_vision_tower: true
vision_tower_name: "facebook/dinov2-base"
use_pretrained_vggt: true
language_model: "Qwen/Qwen3-0.6B-Base"
freeze_vggt: true
batch_size: 16
```

é€‚åˆ:
- æœ€ä½³æ€§èƒ½
- å……è¶³çš„è®¡ç®—èµ„æº
- æœ€ç»ˆæ¨¡å‹è®­ç»ƒ

---

## è®­ç»ƒæŒ‡å—

### ç¯å¢ƒè®¾ç½®

```bash
# 1. å®‰è£…ä¾èµ–
cd vggt_vla
pip install -r requirements.txt

# 2. (å¯é€‰) å®‰è£… VGGT
cd ../vggt
pip install -e .
cd ../vggt_vla
```

### å¿«é€Ÿå¼€å§‹

```bash
# ä½¿ç”¨ç®€åŒ–é…ç½®
bash scripts/quick_start.sh configs/train_simple.yaml

# ä½¿ç”¨ DINOv2
bash scripts/quick_start.sh configs/train_with_dinov2.yaml

# ä½¿ç”¨å®Œæ•´é…ç½®
bash scripts/quick_start.sh configs/train_full.yaml
```

### è‡ªå®šä¹‰è®­ç»ƒ

```bash
python scripts/train_vla.py \
  --dataset_repo lerobot/libero_spatial_image \
  --use_vision_tower \
  --vision_tower_name facebook/dinov2-base \
  --freeze_vision_tower \
  --language_model Qwen/Qwen3-0.6B-Base \
  --freeze_language \
  --batch_size 24 \
  --num_epochs 100 \
  --lr 5e-5 \
  --log_dir ./logs \
  --exp_name my_experiment
```

### æ•°æ®é›†

æ”¯æŒçš„æ•°æ®é›†:
- `lerobot/libero_spatial_image` - LIBERO spatial reasoning tasks
- `lerobot/libero_object` - LIBERO object manipulation
- `lerobot/libero_goal` - LIBERO goal-conditioned tasks
- æˆ–ä»»ä½• HuggingFace æ ¼å¼çš„æœºå™¨äººæ•°æ®é›†

### ç›‘æ§è®­ç»ƒ

é…ç½®ä¸­è®¾ç½® `use_wandb: true`ï¼Œåœ¨ wandb.ai æŸ¥çœ‹æ›²çº¿ï¼›æˆ–æŸ¥çœ‹ `log_dir` ä¸‹çš„ `train_*.log` æ–‡æœ¬æ—¥å¿—ã€‚

ç›‘æ§æŒ‡æ ‡ï¼ˆwandb / æ–‡æœ¬æ—¥å¿—ï¼‰:
- `train/loss`: è®­ç»ƒæŸå¤±
- `val_loss`: éªŒè¯æŸå¤±
- `val/action_mse`: åŠ¨ä½œé¢„æµ‹ MSE
- `val/action_mae`: åŠ¨ä½œé¢„æµ‹ MAE

### æ¨¡å‹è¯„ä¼°

```bash
python scripts/eval.py \
  --checkpoint logs/my_experiment/best_model.pth \
  --dataset_repo lerobot/libero_spatial_image \
  --device cuda
```

---

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆæœ‰ä¸¤ä¸ª VGGT å®ç°?

**A**: 
- `VGGTAdapter`: é€‚é… facebook/vggt (HuggingFace)ï¼Œç”¨äºåˆ©ç”¨é¢„è®­ç»ƒæƒé‡
- `SimpleVGGTBackbone`: ç®€åŒ–å®ç°ï¼Œç”¨äºå¿«é€Ÿå®éªŒå’Œè°ƒè¯•

ä¸¤è€…éƒ½æ”¯æŒå¤šæ¨¡æ€èåˆï¼Œä½† `VGGTAdapter` æ›´å¤æ‚ï¼Œå‚æ•°æ›´å¤šã€‚

### Q2: Vision tower åº”è¯¥é€‰æ‹©å“ªä¸ª?

**A**: 
- **DINOv2**: æ¨èç”¨äºæœºå™¨äººä»»åŠ¡ï¼Œç©ºé—´ç†è§£èƒ½åŠ›å¼º
- **CLIP**: é€‚åˆ vision-language å¯¹é½
- **SigLIP**: CLIP çš„æ”¹è¿›ç‰ˆï¼Œæ€§èƒ½æ›´å¥½

å»ºè®®: ä» DINOv2-base å¼€å§‹ã€‚

### Q3: æ˜¯å¦åº”è¯¥å†»ç»“é¢„è®­ç»ƒæ¨¡å‹?

**A**:
- **Vision Tower**: å»ºè®®å†»ç»“ (æ•°æ®é‡ä¸è¶³æ—¶)
- **Language Model**: å»ºè®®å†»ç»“ (è®¡ç®—èµ„æºæœ‰é™æ—¶)
- **VGGT**: å¦‚æœä½¿ç”¨é¢„è®­ç»ƒï¼Œå»ºè®®å†»ç»“ï¼Œåªè®­ç»ƒé€‚é…å±‚

### Q4: å†…å­˜ä¸è¶³æ€ä¹ˆåŠ?

**A**:
```bash
# æ–¹æ³• 1: å‡å° batch size
--batch_size 16  # æˆ–æ›´å°

# æ–¹æ³• 2: ä½¿ç”¨æ›´å°çš„æ¨¡å‹
--vision_tower_name facebook/dinov2-small
--language_model Qwen/Qwen2-0.5B

# æ–¹æ³• 3: å†»ç»“æ›´å¤šå‚æ•°
--freeze_vision_tower
--freeze_language
--freeze_vggt

# æ–¹æ³• 4: ä½¿ç”¨ç®€åŒ–é…ç½®
--config configs/train_simple.yaml
```

### Q5: è®­ç»ƒä¸æ”¶æ•›æ€ä¹ˆåŠ?

**A**:
1. æ£€æŸ¥æ•°æ®: ç¡®ä¿ actions åœ¨åˆç†èŒƒå›´å†…
2. è°ƒæ•´å­¦ä¹ ç‡: å°è¯• 1e-5 åˆ° 1e-4
3. å¢åŠ  warmup: å‰å‡ ä¸ª epoch ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
4. æ£€æŸ¥æ¢¯åº¦: å¯èƒ½éœ€è¦è°ƒæ•´ `grad_clip`
5. å¯è§†åŒ–: ä½¿ç”¨ TensorBoard æ£€æŸ¥æŸå¤±æ›²çº¿

### Q6: å¦‚ä½•ä½¿ç”¨æœ¬åœ°æ•°æ®?

**A**:
ä¿®æ”¹ `data/libero_dataset.py` æˆ– `data/libero_hf_dataset.py`ï¼Œæ”¯æŒä»æœ¬åœ° HDF5 æ–‡ä»¶åŠ è½½:

```python
from data.libero_dataset import get_libero_dataloaders

train_loader, val_loader = get_libero_dataloaders(
    data_path="/path/to/local/libero_data.hdf5",
    task_names=["pick_and_place"],
    batch_size=32,
    action_horizon=10
)
```

### Q7: å¦‚ä½• fine-tune å·²æœ‰æ¨¡å‹?

**A**:
```bash
python scripts/train_vla.py \
  --config configs/train_simple.yaml \
  --resume logs/previous_experiment/best_model.pth
```

(éœ€è¦åœ¨ trainer ä¸­æ·»åŠ  resume åŠŸèƒ½)

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®åŠ è½½
- ä½¿ç”¨ `num_workers=4` æˆ–æ›´å¤š
- é¢„åŠ è½½æ•°æ®åˆ°å†…å­˜ (å¦‚æœæ•°æ®é›†ä¸å¤§)
- ä½¿ç”¨ `pin_memory=True`

### 2. æ¨¡å‹ä¼˜åŒ–
- ä½¿ç”¨ `torch.compile()` (PyTorch 2.0+)
- æ··åˆç²¾åº¦è®­ç»ƒ (`torch.cuda.amp`)
- æ¢¯åº¦ç´¯ç§¯ (æ¨¡æ‹Ÿæ›´å¤§çš„ batch size)

### 3. åˆ†å¸ƒå¼è®­ç»ƒ
- å¤š GPU: `torchrun` æˆ– `accelerate`
- æ•°æ®å¹¶è¡Œ: `DistributedDataParallel`

---

## æ€»ç»“

### æ¶æ„ä¼˜åŠ¿
1. âœ… **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªç»„ä»¶å¯ç‹¬ç«‹æ›¿æ¢
2. âœ… **çµæ´»é…ç½®**: æ”¯æŒå¤šç§é¢„è®­ç»ƒæ¨¡å‹ç»„åˆ
3. âœ… **å¤šæ¨¡æ€èåˆ**: æœ‰æ•ˆå¤„ç† vision + language
4. âœ… **å¯æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°çš„ vision tower æˆ– language model

### å¤šæ¨¡æ€å¤„ç†æ”¹è¿›
1. âœ… æ”¯æŒ HuggingFace çš„ facebook/vggt
2. âœ… é€‚é…å±‚å¤„ç†è¾“å…¥è¾“å‡ºä¸åŒ¹é…
3. âœ… Token type embeddings åŒºåˆ†æ¨¡æ€
4. âœ… Graph structure ä¿ç•™ spatial/sequential ä¿¡æ¯
5. âœ… Action queries æå–ä»»åŠ¡ç›¸å…³ç‰¹å¾

### ä¸‹ä¸€æ­¥
1. åœ¨ LIBERO æ•°æ®é›†ä¸Šè®­ç»ƒ
2. å¯¹æ¯”ä¸åŒé…ç½®çš„æ€§èƒ½
3. åœ¨çœŸå®æœºå™¨äººä¸Šè¯„ä¼°
4. æ¢ç´¢æ›´å¤šçš„èåˆç­–ç•¥ (cross-attention, gating)

---

**ä½œè€…**: VLA-VGGT Team  
**æ—¥æœŸ**: 2024  
**ç‰ˆæœ¬**: 1.0
