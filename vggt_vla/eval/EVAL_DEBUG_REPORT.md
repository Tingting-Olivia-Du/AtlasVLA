# LIBERO Eval å¤±è´¥åŸå› åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æ‰€æœ‰ eval ä»»åŠ¡å¤±è´¥çš„**æ ¹æœ¬åŸå› **ï¼š**æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥å¯¼è‡´æ¨¡å‹æ— æ³•è¿›è¡Œæœ‰æ•ˆæ¨ç†**

---

## ğŸ”´ æ ¸å¿ƒé—®é¢˜ï¼šè¯­è¨€æ¨¡å‹é…ç½®ä¸åŒ¹é…

### é—®é¢˜æè¿°

å½“è¿è¡Œ eval æ—¶ï¼Œæ¨¡å‹æƒé‡åŠ è½½å¤±è´¥ï¼Œäº§ç”Ÿå¤§é‡ç»´åº¦ä¸åŒ¹é…é”™è¯¯ï¼š

```
size mismatch for language_encoder.language_model.layers.0.self_attn.q_proj.weight:
  copying a param with shape torch.Size([2048, 1024]) from checkpoint,
  the shape in current model is torch.Size([896, 896]).
```

### æ ¹æœ¬åŸå› 

**Checkpoint ä½¿ç”¨çš„æ˜¯ Qwen3-0.6Bï¼Œä½†å½“å‰ç¯å¢ƒä¸­ Qwen3 ä¸å¯ç”¨ï¼Œä»£ç  fallback åˆ° Qwen2-0.5B**

| æ¨¡å‹ | Hidden Size | çŠ¶æ€ |
|------|-------------|------|
| Qwen3-0.6B (Checkpointä¸­) | 1024 | âŒ ä¸å¯ç”¨ï¼ˆTransformersä¸æ”¯æŒï¼‰ |
| Qwen2-0.5B (Fallback) | 896 | âœ… å¯ç”¨ï¼ˆå½“å‰ç¯å¢ƒä¸­ä½¿ç”¨ï¼‰ |

### ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ

1. **Checkpoint ä¿å­˜æ—¶**ï¼ˆè®­ç»ƒæ—¶ï¼‰ï¼šä½¿ç”¨äº† Qwen3-0.6B
   - è¯­è¨€æ¨¡å‹ hidden_size: 1024
   - æŠ•å½±å±‚è¾“å…¥ç»´åº¦: 1024
   - æƒé‡å½¢çŠ¶éƒ½æ˜¯åŸºäº 1024 çš„

2. **Checkpoint åŠ è½½æ—¶**ï¼ˆeval æ—¶ï¼‰ï¼š
   - å°è¯•åŠ è½½ Qwen3-0.6Bï¼Œå¤±è´¥ï¼ˆæç¤º"qwen3 architecture not recognized"ï¼‰
   - ä»£ç  fallback åˆ° Qwen2-0.5B
   - Qwen2-0.5B hidden_size: 896
   - åˆ›å»ºçš„æŠ•å½±å±‚è¾“å…¥ç»´åº¦: 896
   - **æƒé‡å½¢çŠ¶ä¸åŒ¹é…** â†’ `load_state_dict(strict=True)` å¤±è´¥

### é”™è¯¯æ—¥å¿—ä½ç½®

æ–‡ä»¶ï¼š`/workspace/02042026_tingting/AtlasVLA/vggt_vla/eval/debug_eval.py`
è¾“å‡ºï¼š`/root/.claude/projects/-workspace-02042026-tingting-AtlasVLA/f99044e9-69d9-4f87-a1ac-946470eddc40/tool-results/be0da36.txt`

---

## ğŸ“Š é…ç½®ä¿¡æ¯

### Checkpoint ä¸­çš„é…ç½®
```
language_model: Qwen/Qwen3-0.6B-Base
hidden_dim: 768
vggt.embed_dim: 768
language.output_dim: 768
```

### å½“å‰ä»£ç ä¸­çš„é…ç½®ï¼ˆfallbackåï¼‰
```
language_model: Qwen/Qwen2-0.5B  (fallback)
language_hidden_size: 896 (å®é™…çš„Qwen2-0.5B)
target output_dim: 768
```

### æŠ•å½±å±‚å°ºå¯¸ä¸åŒ¹é…
- Checkpointä¸­çš„æŠ•å½±å±‚ï¼š`Linear(1024 â†’ 768)`
- å½“å‰ä»£ç ä¸­åˆ›å»ºçš„æŠ•å½±å±‚ï¼š`Linear(896 â†’ 768)`

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šæ›´æ–° Transformers ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
å¦‚æœ Qwen3 æ˜¯æ–°çš„æ¨¡å‹ï¼Œéœ€è¦å‡çº§ Transformers æ¥æ”¯æŒå®ƒã€‚

```bash
pip install --upgrade transformers
```

**ä¼˜ç‚¹**ï¼š
- æ¢å¤åŸå§‹è®­ç»ƒé…ç½®
- æƒé‡å®Œå…¨åŒ¹é…
- æ¨¡å‹æ€§èƒ½æœ€ä½³

**å¯èƒ½çš„é£é™©**ï¼š
- å¯èƒ½å½±å“å…¶ä»–ä¾èµ–

### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨å…¼å®¹ Checkpointï¼ˆå¿«é€Ÿä¿®å¤ï¼‰
é‡æ–°ç”¨ Qwen2-0.5B è®­ç»ƒæ¨¡å‹ï¼Œæˆ–è½¬æ¢ checkpointã€‚

**æµç¨‹**ï¼š
1. ä¿®æ”¹ checkpoint ä¸­çš„é…ç½®ï¼Œå°†è¯­è¨€æ¨¡å‹æ”¹ä¸º Qwen2-0.5B
2. ä½¿ç”¨ç‰¹æ®Šçš„åŠ è½½é€»è¾‘å¤„ç†ç»´åº¦ä¸åŒ¹é…

**å®ç°ä»£ç **ï¼ˆåœ¨ `eval_vla_libero.py` ä¸­ï¼‰ï¼š
```python
# ä¿®æ”¹ load_model_and_config å‡½æ•°
try:
    model.load_state_dict(state_dict, strict=True)
except RuntimeError as e:
    if 'size mismatch' in str(e) and 'language' in str(e):
        # å°è¯•ä½¿ç”¨ strict=False åŠ è½½ï¼Œç„¶åæ‰‹åŠ¨å¤„ç†
        print("Language model dimension mismatch detected.")
        print("Loading with strict=False and re-initializing mismatched layers...")
        model.load_state_dict(state_dict, strict=False)
        # é‡æ–°åˆå§‹åŒ–è¢«å¿½ç•¥çš„å±‚ï¼Œä½†è¿™å¯èƒ½å½±å“æ€§èƒ½
```

### æ–¹æ¡ˆ 3ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ Qwen3 çš„è½»é‡çº§æ›¿ä»£å“

Qwen3-0.6B å¦‚æœä¸å¯ç”¨ï¼Œå¯ä»¥å¯»æ‰¾å…¶ä»–ç±»ä¼¼è§„æ¨¡çš„æ¨¡å‹ï¼š
- `meta-llama/Llama-2-7b` (å¤§ä¸€ç‚¹)
- `mistralai/Mistral-7B` (å¤§ä¸€ç‚¹)
- `Qwen/Qwen2-1.5B` (å¤§ä¸€ç‚¹)

---

## ğŸ“ ç›¸å…³ä»£ç ä½ç½®

### è¯­è¨€ç¼–ç å™¨ï¼ˆæœ‰ fallback é€»è¾‘ï¼‰
æ–‡ä»¶ï¼š[vggt_vla/models/language_encoder.py:30-41](vggt_vla/models/language_encoder.py#L30-L41)

```python
try:
    self.language_model = AutoModel.from_pretrained(
        config.model_name,
        trust_remote_code=True
    )
except Exception as e:
    print(f"Warning: Could not load model from {config.model_name}: {e}")
    print("Falling back to Qwen2-0.5B...")
    self.language_model = AutoModel.from_pretrained(
        "Qwen/Qwen2-0.5B",
        trust_remote_code=True
    )
```

### Checkpoint åŠ è½½é€»è¾‘ï¼ˆstrict=Trueï¼‰
æ–‡ä»¶ï¼š[vggt_vla/eval/eval_vla_libero.py:148](vggt_vla/eval/eval_vla_libero.py#L148)

```python
model.load_state_dict(state_dict, strict=True)  # ä¸¥æ ¼æ¨¡å¼å¯¼è‡´å¤±è´¥
```

---

## âœ… å»ºè®®çš„å¿«é€Ÿä¿®å¤æ­¥éª¤

1. **ç«‹å³**ï¼šä½¿ç”¨ `strict=False` åŠ è½½æƒé‡
2. **æµ‹è¯•**ï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½æ˜¯å¦é™ä½
3. **é•¿æœŸ**ï¼š
   - å‡çº§ Transformers
   - æˆ–é‡æ–°ç”¨ Qwen2-0.5B è®­ç»ƒæ¨¡å‹

---

## ğŸ§ª éªŒè¯æ–¹æ³•

è¿è¡Œè°ƒè¯•è„šæœ¬éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸï¼š
```bash
python vggt_vla/eval/debug_eval.py
```

é¢„æœŸè¾“å‡ºåº”è¯¥åŒ…å«ï¼š
```
âœ“ Model loaded to cuda:0
âœ“ Forward pass successful
âœ“ Actions are deterministic
âœ“ Task completed at step X!
```

---

## ğŸ“Œ æ€»ç»“

| é—®é¢˜ | åŸå›  | å½±å“ | ä¿®å¤ |
|------|------|------|------|
| æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥ | Qwen3 ä¸å¯ç”¨ï¼Œfallback åˆ° Qwen2 | æ‰€æœ‰ä»»åŠ¡å¤±è´¥ | å‡çº§ Transformers |
| è¯­è¨€æ¨¡å‹ç»´åº¦ä¸åŒ¹é… | 1024 vs 896 | æƒé‡æ— æ³•åŠ è½½ | strict=False æˆ–é‡è®­ |
| Eval æˆåŠŸç‡ 0% | æ¨¡å‹æ¨ç†æ— æ•ˆ | æ— æ³•è¯„ä¼°æ¨¡å‹ | è§£å†³åŠ è½½é—®é¢˜ |
